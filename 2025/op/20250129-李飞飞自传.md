## 李飞飞自传

出生在北京，在成都长大。

“我们家位于成都当时的外环路旁边，小区由三栋一模一样的塔楼组成，我家住在四楼。这个环路是不断扩张的城市边缘，一侧是工业，另一侧是农业。就像这座城市本身一样，居民楼也更加注重功能而非设计——白炽灯、水泥地，在现代人眼里或许显得过于简朴。越来越多的家庭选择粉刷墙面，用仿实木或仿彩色瓷砖的贴面板铺设地面，这些装饰虽然在一定程度上打破了视觉上的单调，却难以掩盖苏联风格的影响。”

终于，在1992年，我刚满15岁不久，我们的签证下来了。我们在中国的时间只剩下最后几个月了，

### 1956年：人工智能的提出

早在那个年代，阿兰·图灵（Alan Turing，英国密码破译专家，因帮助结束了第二次世界大战而闻名于世）等先驱科学家就已经发现了机器和人脑的相似之处，其所展现的突破性想象力与引领前人科学革命的物理学家相比毫不逊色。与爱因斯坦、玻尔和薛定谔一样，图灵和他同时代的人提出的问题直到今天仍能引发激烈的争论。智能到底是什么？可以用定量的机械方式解构智能吗？最大胆的问题也许是，我们有能力制造可以体现智能的机器吗？

灵的设想得到了美国计算机科学家同行的呼应。1956年，他们将好奇心编撰成文，提出了现在广为人知的《达特茅斯人工智能夏季研究项目提案》，“人工智能”一词就是在这份提案中诞生的。提案呼吁举办一次非正式研讨会，探讨如何通过计算机编程来完成类似人类的推理、感知和知识概括等活动。项目主要由约翰·麦卡锡（John McCarthy）和马文·明斯基（Marvin Minsky）主导，他们二位都是长期对大脑保持好奇心的数学家；此外还有IBM 701计算机的设计者纳撒尼尔·罗切斯特（Nathaniel Rochester），以及被誉为“信息论之父”的克劳德·香农（Claude Shannon）。

他们看来，人类的推理能力可以完美类比计算机程序：不过是逻辑规则的产物而已。他们设想，一旦对相关规则的理解趋于完善，任何一台遵循这些规则的机器都能够自然识别照片内容、理解人类语言、探索抽象概念，甚至创造性地解决新问题。

达特茅斯研究小组很快发现，尽管我们行为的方方面面确实可以用简单的术语来描述，但人类思想的深度和多变却无法简单归纳为一套规则或标准，至少在实际操作中是不可行的。

### 1959年：神经网络

1958年就迎来了这样一个时刻。康奈尔航空实验室的心理学研究员弗兰克·罗森布拉特（Frank Rosenblatt）发明了一种机械神经元，他称之为“感知机”（perceptron）。

1959年，神经生理学家戴维·休伯尔（David Hubel）和托斯登·威塞尔（Torsten Wiesel）在哈佛大学进行了一项开创性的研究，研究了哺乳动物的大脑，特别是猫的视觉皮质。实验在暗室里进行，研究人员将基本形状的图画投射到墙壁上，精确控制猫所看到的东西，包括线条、缝隙和其他简单的细节，并仔细观察其神经元的反应方式。

哺乳动物通过神经元形成的神经网络，形成感知的理论，也就是建立了神经网络理论。

但是，只是提出了这个概念，没有实际的算法。

### 1986年：提出神经网络的具体算法

1986年，由加州大学圣迭戈分校教授大卫·鲁梅尔哈特（David E. Rumelhart）领导的一个研究人员小组在科学杂志《自然》（Nature）上发表短篇研究报告，介绍了一种能让新认知机等算法有效学习的技术。他们将其称为“反向传播”（backpropagation），名字来源于这一技术最显著的特征：在这种级联效应中，每个训练实例（具体来说，是网络对给定刺激的反应与正确答案之间的差异）通过网络的一端传递到另一端，并逐层进行误差的递减调整。

通过不断调整误差，使得误差逐层递减。

提出多层神经网络的新处理方法，使得神经网络处理复杂问题称为可能。

“虽然鲁梅尔哈特是首席研究员，但他的两位合著者之一杰弗里·辛顿（Geoffrey Hinton）才是与反向传播联系最紧密的人物。辛顿当时是卡内基梅隆大学的教授，从小就被智能之谜所吸引，其职业生涯致力于探索重现智能的新方法。他孜孜不倦地探索各种新颖的机器学习方法，为这一领域的早期复兴做出了巨大贡献。那是一个神经网络稳步发展的时代，网络层数越来越多，神经元连接越来越复杂，训练技术也越来越完善。

### 杨立昆

杨立昆是辛顿的第一批学生，他把这些研究成果应用到了识别手写邮编这一极具实用性的场景，引起广泛关注。在不到十年的时间里，机器学习这样一个曾经遥不可及的梦想终于在现实世界中开花结果。

人工智能的第一个实用性成就：识别人类字迹，时间为80年代末90年代初

让算法从大量数据中推断出解决问题的模式，算法不是被告知该做什么，而是去学习该做什么。研究人员给它起了一个贴切的名字：“机器学习”（machine learning）。”

杨立昆（Yann LeCun）会成为脸书的人工智能首席科学家，但在我们到达美国时，他在新泽西州霍姆德尔的贝尔实验室的研究生涯才刚刚起步。他为人谦逊但雄心勃勃，近些年引发了不小的轰动，因为他展示了“神经网络”（neural network）算法在准确识别人类笔迹方面的能力。尽管这项技术仍然相对较新，远未达到日后的普及程度，但与之前数十年的人工智能传统已经截然不同。神经网络算法的目标不是用离散的规则来描述笔迹（1是直的，2是弯的，3是对称的，诸如此类），而是从数据中推断出模式。

杨立昆从美国邮政署拿到了7200多个手写邮编的扫描件，涵盖各种风格、质地，甚至包括常见的错误。他向神经网络算法展示这几千个真实的人类笔迹，让机器也能像人类一样学习相关模式，形成内化的直觉。这套直觉很难用传统计算机程序的形式表达，但它使得算法能够以前所未有的方式理解真实世界的复杂混乱。”

杨立昆的研究取得了巨大的成功。算法的识别非常精准，在短短几年内，它就被广泛应用于全美的自动提款机上，用来读取支票上的数字。在距离达特茅斯研究提案中首次提出人工智能概念几十年后，人工智能领域终于取得了极具实用性的成就。

此前的几代人试图用规则详尽描述智能，算法相对僵化，这种人工智能通常被称为“符号人工智能”（symbolic AI）；20世纪80年代末到90年代初，潮流开始转向更自然的方法。杨立昆的成果就预示着一个大胆的未来。随着时间的推移，行业研究重点从“通过明确编程来解决问题”转变为“从示例中发现模式”。换言之，算法不是被告知该做什么，而是去学习该做什么。研究人员给它起了一个贴切的名字：“机器学习”（machine learning）。”

### 90年代早期

无论是对受过训练还是没有受过训练的观察者来说，20世纪90年代早期无疑都象征着一个全新时代的来临。辛顿的反向传播技术似乎为神经网络提供了最后一块拼图，而杨立昆在手写数字识别方面的成功，则为算法在现实世界中的应用提供了无懈可击的验证。一种近乎神奇的工程范式已经到来，在这种范式中，类似人类的有机感知可以像数据库或文件服务器一样被精心设计出来。但是，麻烦再一次显露端倪。刚刚起步的人工智能领域很快就会发现，充满了失败尝试和希望破灭的日子尚未结束。

尽管神经网络的潜力显而易见，但除了在识别邮政编码方面取得成功，它在其他场景中的应用很快就陷入困境。原因是多方面的。首先，尽管在白板上绘制的算法在概念上非常优雅，但就算是很简单的实现，所需的计算量也非常惊人，甚至远远超出大多数企业和政府的能力范围。此外，数字数据的可用性也是令人担忧的问题。在当时，数字数据相对稀缺，尤其是图像、视频、音频等感知数据。当时大部分数据都是碎片化的独家数据，而且存储于私人服务器中，编目不统一。无论神经网络注定要实现什么目标，很明显，此时时机还不成熟。

不久之后，“人工智能寒冬”来临，研究界失去了方向和支撑，进入了一个漫长的低迷期。甚至有人认为“人工智能”这个词本身过于宽泛，是一种妄想。人工智能的能力被淡化，研究人员转向了更加狭隘的领域，如决策、模式识别和自然语言处理（旨在理解人类的语言和文字）。“人工智能”似乎注定只是科幻小说家的沃土，而不是学者的领域。就像物理学的发展史会随着发现的大幅度起伏而呈现出正弦曲线一样，人工智能的发展也充满了起起伏伏。

杨立昆和辛顿都是先驱，这一点毋庸置疑。但他们能否在活着的时候见证自己的想法改变世界，还是个未知数。两人都继续专注于研究，与此同时，世界仍在不断向前，找寻着更简单、更高效、更节省人力的解决方案。简单来说，神经网络是个很好的概念，只是生不逢时。