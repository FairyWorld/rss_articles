## 李飞飞自传

出生在北京，在成都长大。

“我们家位于成都当时的外环路旁边，小区由三栋一模一样的塔楼组成，我家住在四楼。这个环路是不断扩张的城市边缘，一侧是工业，另一侧是农业。就像这座城市本身一样，居民楼也更加注重功能而非设计——白炽灯、水泥地，在现代人眼里或许显得过于简朴。越来越多的家庭选择粉刷墙面，用仿实木或仿彩色瓷砖的贴面板铺设地面，这些装饰虽然在一定程度上打破了视觉上的单调，却难以掩盖苏联风格的影响。”

终于，在1992年，我刚满15岁不久，我们的签证下来了。我们在中国的时间只剩下最后几个月了，

### 1956年：人工智能的提出

早在那个年代，阿兰·图灵（Alan Turing，英国密码破译专家，因帮助结束了第二次世界大战而闻名于世）等先驱科学家就已经发现了机器和人脑的相似之处，其所展现的突破性想象力与引领前人科学革命的物理学家相比毫不逊色。与爱因斯坦、玻尔和薛定谔一样，图灵和他同时代的人提出的问题直到今天仍能引发激烈的争论。智能到底是什么？可以用定量的机械方式解构智能吗？最大胆的问题也许是，我们有能力制造可以体现智能的机器吗？

灵的设想得到了美国计算机科学家同行的呼应。1956年，他们将好奇心编撰成文，提出了现在广为人知的《达特茅斯人工智能夏季研究项目提案》，“人工智能”一词就是在这份提案中诞生的。提案呼吁举办一次非正式研讨会，探讨如何通过计算机编程来完成类似人类的推理、感知和知识概括等活动。项目主要由约翰·麦卡锡（John McCarthy）和马文·明斯基（Marvin Minsky）主导，他们二位都是长期对大脑保持好奇心的数学家；此外还有IBM 701计算机的设计者纳撒尼尔·罗切斯特（Nathaniel Rochester），以及被誉为“信息论之父”的克劳德·香农（Claude Shannon）。

他们看来，人类的推理能力可以完美类比计算机程序：不过是逻辑规则的产物而已。他们设想，一旦对相关规则的理解趋于完善，任何一台遵循这些规则的机器都能够自然识别照片内容、理解人类语言、探索抽象概念，甚至创造性地解决新问题。

达特茅斯研究小组很快发现，尽管我们行为的方方面面确实可以用简单的术语来描述，但人类思想的深度和多变却无法简单归纳为一套规则或标准，至少在实际操作中是不可行的。

### 1959年：神经网络

1958年就迎来了这样一个时刻。康奈尔航空实验室的心理学研究员弗兰克·罗森布拉特（Frank Rosenblatt）发明了一种机械神经元，他称之为“感知机”（perceptron）。

1959年，神经生理学家戴维·休伯尔（David Hubel）和托斯登·威塞尔（Torsten Wiesel）在哈佛大学进行了一项开创性的研究，研究了哺乳动物的大脑，特别是猫的视觉皮质。实验在暗室里进行，研究人员将基本形状的图画投射到墙壁上，精确控制猫所看到的东西，包括线条、缝隙和其他简单的细节，并仔细观察其神经元的反应方式。

哺乳动物通过神经元形成的神经网络，形成感知的理论，也就是建立了神经网络理论。

但是，只是提出了这个概念，没有实际的算法。

### 1986年：提出神经网络的具体算法

https://computerhistory.org/blog/chm-releases-alexnet-source-code/

杰弗里·辛顿被认为是“深度学习”之父之一。深度学习是一种使用神经网络的人工智能，也是当今主流人工智能的基础。20 世纪 50 年代末，康奈尔大学研究员弗兰克·罗森布拉特首次构建了简单的三层神经网络，其中只有一层自适应权重，但人们发现它们存在局限性。需要具有多层自适应权重的网络，但没有很好的方法来训练它们。到 20 世纪 70 年代初，神经网络已被人工智能研究人员普遍拒绝。

20 世纪 80 年代，加州大学圣地亚哥分校的认知科学家在人工智能社区之外以“联结主义”为新名称复兴了神经网络研究。获得博士学位后，Hinton 成为圣地亚哥大学的博士后研究员，与 David Rumelhart 和 Ronald Williams 合作。他们重新发现了用于训练多层神经网络的反向传播算法，并于 1986 年发表了两篇论文，表明该算法可使神经网络学习多层特征，以完成语言和视觉任务。反向传播利用网络当前输出和期望输出之间的差异来调整从输出层到输入层的每一层的权重。有关神经网络工作原理的更多详细信息，请参见此处。“反向传播”是当今深度学习的基础。

1987 年，Hinton 加入多伦多大学。远离传统人工智能中心，Hinton 及其研究生在接下来的几十年里所做的工作使多伦多成为深度学习研究中心。当时 Hinton 的博士后学生是 Yann LeCun。在多伦多工作期间，他证明了当反向传播用于“卷积”神经网络时，它们在识别手写数字方面变得非常出色。

尽管取得了这些进步，神经网络仍无法持续超越其他类型的机器学习算法。它们需要人工智能之外的两项发展来铺平道路。第一是网络提供的大量训练数据。第二是 GPU 硬件提供足够的计算能力来进行这种训练。到 2012 年，AlexNet 的时机已经成熟。

训练 AlexNet 所需的大量精心挑选的数据来自斯坦福大学教授李飞飞发起并领导的 ImageNet 项目。从 2006 年开始，她一反传统观念，设想了一个涵盖英语中所有名词的图像数据集。她和她的研究生首先收集在互联网上找到的图像，并使用 WordNet（一个包含单词及其相互关系的数据库）提供的分类法对它们进行分类。鉴于任务的艰巨性，李飞飞和她的合作者最终使用亚马逊的 Mechanical Turk 平台将标记图像的任务众包给零工。

ImageNet 于 2009 年完成，比之前的任何图像数据集都大几个数量级。李飞飞希望它的出现能带来新的突破，并于 2010 年发起了一项竞赛，鼓励研究团队改进他们的图像识别算法。然而，在头两年之后，最好的系统也只是取得了微小的进步。

神经网络成功的第二个必要条件是经济地获取大量计算。神经网络训练涉及大量重复的矩阵乘法，最好是并行完成，这是 3D 图形芯片（称为 GPU）的设计目的。由联合创始人兼首席执行官黄仁勋领导的 NVIDIA 在 21 世纪率先使 GPU 更具通用性和可编程性，可用于 3D 图形以外的应用，尤其是 2007 年发布的 CUDA 编程系统。

到 2000 年代后期，Hinton 在多伦多大学的研究生开始使用 GPU 来训练神经网络，以完成图像和语音识别任务。他们的第一个成功来自语音识别，但在图像识别方面的成功表明深度学习可能是 AI 的通用解决方案。一名学生 Ilya Sutskever 认为，神经网络的性能将随着可用数据量的增加而增长，而 ImageNet 的出现提供了这个机会。

2011 年，Sutskever 说服了研究生同学 Alex Krizhevsky（他非常善于从 GPU 中榨取最大性能）为 ImageNet 训练卷积神经网络，Hinton 担任首席研究员。Krizhevsky 已经使用 NVIDIA GPU 为卷积神经网络编写了 CUDA 代码，称为“cuda-convnet”，在规模小得多的 CIFAR-10 图像数据集上进行训练。他扩展了 cuda-convnet，使其支持多个 GPU 和其他功能，并在 ImageNet 上对其进行了重新训练。训练是在 Krizhevsky 父母家中卧室的一台装有两张 NVIDIA 显卡的计算机上进行的。在接下来的一年里，Krizhevsky 不断调整网络的参数并对其进行重新训练，直到其性能优于竞争对手。该网络最终以 Krizhevsky 的名字命名为 AlexNet。在描述 AlexNet 项目时，Geoff Hinton 为 CHM 总结道：“Ilya 认为我们应该做这件事，Alex 让它成功了，而我获得了诺贝尔奖。”

Krizhevsky、Sutskever 和 Hinton 的论文发表于 2012 年秋季，并于 10 月在意大利佛罗伦萨举行的计算机视觉会议上由 Krizhevsky 公开发表。资深计算机视觉研究人员并不相信，但出席会议的 Yann LeCun 宣布这是人工智能的转折点。他是对的。在 AlexNet 之前，几乎没有一篇领先的计算机视觉论文使用神经网络。在它之后，几乎所有论文都会使用神经网络。

AlexNet 只是一个开始。在接下来的十年里，神经网络将不断进步，合成可信的人类声音、击败围棋冠军选手、模拟人类语言并生成艺术作品，最终由 Sutskever 共同创办的公司 OpenAI 于 2022 年发布 ChatGPT。

---

1986年，由加州大学圣迭戈分校教授大卫·鲁梅尔哈特（David E. Rumelhart）领导的一个研究人员小组在科学杂志《自然》（Nature）上发表短篇研究报告，介绍了一种能让新认知机等算法有效学习的技术。他们将其称为“反向传播”（backpropagation），名字来源于这一技术最显著的特征：在这种级联效应中，每个训练实例（具体来说，是网络对给定刺激的反应与正确答案之间的差异）通过网络的一端传递到另一端，并逐层进行误差的递减调整。

通过不断调整误差，使得误差逐层递减。

提出多层神经网络的新处理方法，使得神经网络处理复杂问题称为可能。

“虽然鲁梅尔哈特是首席研究员，但他的两位合著者之一杰弗里·辛顿（Geoffrey Hinton）才是与反向传播联系最紧密的人物。辛顿当时是卡内基梅隆大学的教授，从小就被智能之谜所吸引，其职业生涯致力于探索重现智能的新方法。他孜孜不倦地探索各种新颖的机器学习方法，为这一领域的早期复兴做出了巨大贡献。那是一个神经网络稳步发展的时代，网络层数越来越多，神经元连接越来越复杂，训练技术也越来越完善。

### 杨立昆

杨立昆是辛顿的第一批学生，他把这些研究成果应用到了识别手写邮编这一极具实用性的场景，引起广泛关注。在不到十年的时间里，机器学习这样一个曾经遥不可及的梦想终于在现实世界中开花结果。

人工智能的第一个实用性成就：识别人类字迹，时间为80年代末90年代初

让算法从大量数据中推断出解决问题的模式，算法不是被告知该做什么，而是去学习该做什么。研究人员给它起了一个贴切的名字：“机器学习”（machine learning）。”

杨立昆（Yann LeCun）会成为脸书的人工智能首席科学家，但在我们到达美国时，他在新泽西州霍姆德尔的贝尔实验室的研究生涯才刚刚起步。他为人谦逊但雄心勃勃，近些年引发了不小的轰动，因为他展示了“神经网络”（neural network）算法在准确识别人类笔迹方面的能力。尽管这项技术仍然相对较新，远未达到日后的普及程度，但与之前数十年的人工智能传统已经截然不同。神经网络算法的目标不是用离散的规则来描述笔迹（1是直的，2是弯的，3是对称的，诸如此类），而是从数据中推断出模式。

杨立昆从美国邮政署拿到了7200多个手写邮编的扫描件，涵盖各种风格、质地，甚至包括常见的错误。他向神经网络算法展示这几千个真实的人类笔迹，让机器也能像人类一样学习相关模式，形成内化的直觉。这套直觉很难用传统计算机程序的形式表达，但它使得算法能够以前所未有的方式理解真实世界的复杂混乱。”

杨立昆的研究取得了巨大的成功。算法的识别非常精准，在短短几年内，它就被广泛应用于全美的自动提款机上，用来读取支票上的数字。在距离达特茅斯研究提案中首次提出人工智能概念几十年后，人工智能领域终于取得了极具实用性的成就。

此前的几代人试图用规则详尽描述智能，算法相对僵化，这种人工智能通常被称为“符号人工智能”（symbolic AI）；20世纪80年代末到90年代初，潮流开始转向更自然的方法。杨立昆的成果就预示着一个大胆的未来。随着时间的推移，行业研究重点从“通过明确编程来解决问题”转变为“从示例中发现模式”。换言之，算法不是被告知该做什么，而是去学习该做什么。研究人员给它起了一个贴切的名字：“机器学习”（machine learning）。”

### 90年代早期

无论是对受过训练还是没有受过训练的观察者来说，20世纪90年代早期无疑都象征着一个全新时代的来临。辛顿的反向传播技术似乎为神经网络提供了最后一块拼图，而杨立昆在手写数字识别方面的成功，则为算法在现实世界中的应用提供了无懈可击的验证。一种近乎神奇的工程范式已经到来，在这种范式中，类似人类的有机感知可以像数据库或文件服务器一样被精心设计出来。但是，麻烦再一次显露端倪。刚刚起步的人工智能领域很快就会发现，充满了失败尝试和希望破灭的日子尚未结束。

尽管神经网络的潜力显而易见，但除了在识别邮政编码方面取得成功，它在其他场景中的应用很快就陷入困境。原因是多方面的。首先，尽管在白板上绘制的算法在概念上非常优雅，但就算是很简单的实现，所需的计算量也非常惊人，甚至远远超出大多数企业和政府的能力范围。此外，数字数据的可用性也是令人担忧的问题。在当时，数字数据相对稀缺，尤其是图像、视频、音频等感知数据。当时大部分数据都是碎片化的独家数据，而且存储于私人服务器中，编目不统一。无论神经网络注定要实现什么目标，很明显，此时时机还不成熟。

不久之后，“人工智能寒冬”来临，研究界失去了方向和支撑，进入了一个漫长的低迷期。甚至有人认为“人工智能”这个词本身过于宽泛，是一种妄想。人工智能的能力被淡化，研究人员转向了更加狭隘的领域，如决策、模式识别和自然语言处理（旨在理解人类的语言和文字）。“人工智能”似乎注定只是科幻小说家的沃土，而不是学者的领域。就像物理学的发展史会随着发现的大幅度起伏而呈现出正弦曲线一样，人工智能的发展也充满了起起伏伏。

杨立昆和辛顿都是先驱，这一点毋庸置疑。但他们能否在活着的时候见证自己的想法改变世界，还是个未知数。两人都继续专注于研究，与此同时，世界仍在不断向前，找寻着更简单、更高效、更节省人力的解决方案。简单来说，神经网络是个很好的概念，只是生不逢时。