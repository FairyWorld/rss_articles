## 李飞飞的故事

我给大家理一下深度学习的历史，你就知道那些模型和人物的关系了。

这是生成式 AI 的起源。

它是 算法 + 数据 + 硬件 共同发展的结果，在2010年代，这三个因素同时具备了，缺一不可，从而促成了 AI 的诞生。 

李着迷于计算机视觉算法。决定走得更远。

2007 年 1 月，当李飞飞开始在普林斯顿大学担任计算机科学教授的新工作时，她并没有考虑过神经网络或 GPU。在加州理工学院获得博士学位时，她建立了一个名为 Caltech 101 的数据集，其中包含 9,000跨 101 个类别的图像。

这次经历告诉她，计算机视觉算法往往在更大、更多样化的训练数据集上表现更好。

她对视觉科学家欧文·比德曼 (Irving Biederman) 的估计 ，该估计认为，普通人可以识别大约 30,000 种不同类型的物体。李开始思考是否有可能建立一个真正全面的图像数据集——其中包括人们在物理世界中常见的各种物体。 

https://www.understandingai.org/p/why-the-deep-learning-boom-caught

神经网络 濒于沉寂

Li 将她的新数据集称为 ImageNet，并使用 WordNet 作为选择类别的起点。她消除了动词和形容词以及“真理”等无形名词。这就留下了 22,000 个可数物体的列表，从救护车到西葫芦。 

2007年 普林斯顿大学的一个团队 李飞飞 建立 imageNet

2009 年，当她在斯坦福大学找到新工作时，她带着其中几名学生以及 ImageNet 项目来到了加利福尼亚州。

ImageNet 于 2009 年准备出版， 标识了 1400 万张图像中的每张图像。即用文字描述图像里面的东西是什么。 


ImageNet 在 2009 年发布后的最初几年几乎没有受到关注。

为了引起公众的兴趣，李将 ImageNet 变成了一场竞赛。意识到完整的数据集可能太笨重，无法分发给数十名参赛者，她创建了一个小得多（但仍然庞大）的数据集，其中包含 1,000 个类别和 140 万张图像。

2010 年第一年的比赛引起了极大的关注，共有 11 支队伍参加。获奖作品基于支持向量机。不幸的是，李写道，“与我们领域其他地方发现的尖端工作相比，这只是轻微的改进。” 

ImageNet 竞赛第二年吸引的参赛作品比第一年少。 2011 年的获胜作品是另一个支持向量机，它仅比 2010 年获胜作品的性能略有提高。李开始怀疑批评者是否正确。也许“ImageNet 对于大多数算法来说都难以处理。” 

但在 2012 年，多伦多大学的一个团队在 ImageNet 数据集上训练了一个神经网络，在图像识别方面取得了前所未有的性能。这一开创性的人工智能模型以主要作者 Alex Krizhevsky 的名字命名为 AlexNet，引发了持续至今的深度学习热潮。 

但2012年，当李娜无奈地第三次举办比赛时，结果却截然不同。 Geoff Hinton 的团队是第一个提交基于深度神经网络的模型的团队。它的前 5 名准确率为 85%，比 2011 年的获胜者高出 10 个百分点。 

如果没有 ImageNet 数据集，AlexNet 就不会成功。就无法在实际的数据集上验证。

如果没有 CUDA 平台，AlexNet 也不可能实现，该平台允许 Nvidia 的图形处理单元 (GPU) 用于非图形应用程序。当 Nvidia 在 2006 年宣布 CUDA 时，许多人都持怀疑态度。 

---

数据集 算法 硬件 三者的公共发展，使得深度学习的诞生 多伦多大学计算机科学家杰弗里·辛顿(Geoffrey Hinton)

在 1986 年发表的一篇具有里程碑意义的论文 中，Hinton 与他在加州大学圣地亚哥分校的两位前同事 David Rumelhart 和 Ronald Williams 合作，描述了一种称为 反向传播的 技术，用于有效训练深度神经网络。 

Hinton 于 1987 年搬到多伦多大学，并开始吸引想要研究神经网络的年轻研究人员。第一个是法国计算机科学家 Yann LeCun，他在 1988 年转到贝尔实验室之前跟随 Hinton 做了一年的博士后。 

用来识别银行支票。

硬件：于是在2006年，Nvidia宣布了CUDA平台。 CUDA 允许程序员编写“内核”，即设计在单个执行单元上运行的短程序。内核允许将大型计算任务分割成可以并行处理的小块。这使得某些类型的计算能够比单独使用 CPU 更快地完成。 

黄在创建 CUDA 平台时并没有专门考虑人工智能或神经网络。但事实证明，Hinton 的反向传播算法可以很容易地分成小块。因此，训练神经网络成为 CUDA 的杀手级应用。

尽管受到冷落，Hinton 和他的研究生 Alex Krizhevsky 和 ​​Ilya Sutskever 获得了一对Nvidia GTX 580 GPU 为 AlexNet 项目 。每个 GPU 都有 512 个执行单元，这使得 Krizhevsky 和 ​​Sutskever 训练神经网络的速度比 CPU 快数百倍。这种速度使他们能够训练更大的模型，并在更多的训练图像上进行训练。他们需要所有额外的计算能力来处理庞大的 ImageNet 数据集。 

仅使用两块GeForce NVIDIA GPU卡开发了强大的视觉识别网络AlexNet 。 [ 2 ]这彻底改变了神经网络的研究。以前神经网络是在CPU上训练的。向 GPU 的过渡为高级人工智能模型的开发开辟了道路。 [ 2 ] AlexNet在 2012 年赢得了ImageNet挑战赛。在赢得比赛后不久，Krizhevsky 和 ​​Sutskever 将他们的初创公司 DNN Research Inc. 出售给了Google 。 Krizhevsky 在对工作失去兴趣后于 2

AlexNet 是一种卷积神经网络，是 LeCun 20 年前开发的一种神经网络，用于识别支票上的手写数字。 （有关 CNN 工作原理的更多详细信息，请参阅 我在 2018 年为 Ars Technica 撰写的深入解释文章 。）事实上，AlexNet 和 LeCun 的 20 世纪 90 年代的图像识别网络之间几乎没有架构差异。

AlexNet 只是规模大得多。在 1998 年的一篇论文 中，LeCun 描述了一个具有七层和 60,000 个可训练参数的文档识别网络。 AlexNet 有八层，但这些层有 6000 万个 可训练参数。 

**LeCun 在 20 世纪 90 年代初期不可能训练出这么大的模型，因为当时还没有具有与 2012 年代 GPU 一样强大处理能力的计算机芯片。即使 LeCun 成功建造了一台足够大的超级计算机，他也没有足够的图像来正确训练它。** 在谷歌和亚马逊 Mechanical Turk 出现之前的几年里，收集这些图像的成本非常昂贵。 

尾声：也是一个时代的开始。

技术界立即认识到了 AlexNet 的重要性。辛顿和他的学生成立了一家空壳公司，目标是被一家大型科技公司“收购”，完全是因为这样可以拿到更多的钱。几个月内， 收购了该公司 谷歌以4400万美元 。 Hinton 在接下来的十年里在谷歌工作，同时保留了他在多伦多的学术职位。 Ilya Sutskever 在 Google 工作了几年，之后成为 OpenAI 的联合创始人。

AlexNet 还使 Nvidia GPU 成为训练神经网络的行业标准。 2012年，市场对英伟达的估值还不到100亿美元。如今，Nvidia 是世界上最有价值的公司之一，市值超过 3 万亿美元。这种高估值主要是由于对 H100 等针对训练神经网络进行优化的 GPU 的巨大需求推动的。 

“那一刻对人工智能世界来说非常具有象征意义，因为现代人工智能的三个基本要素首次融合，” 说道 李在 9 月份在计算机历史博物馆接受采访时 。 “第一个元素是神经网络。第二个要素是使用 ImageNet 的大数据。第三个要素是 GPU 计算。” 

